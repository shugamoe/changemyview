{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.decomposition\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.datasets import fetch_20newsgroups, make_blobs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  #Feature extraction\n",
    "from sklearn.naive_bayes import MultinomialNB #Our learner.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "import pandas as pd\n",
    "\n",
    "import nltk #For tokenizing and normalizing\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_pickle('com_data_test.pkl')\n",
    "#df = df.sample(frac = .1)\n",
    "\n",
    "#splitting data\n",
    "data_train, data_test = train_test_split(df, test_size=0.3, random_state=123)\n",
    "data_train['is_train'] = True\n",
    "data_test['is_train'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_text_x</th>\n",
       "      <th>com_text</th>\n",
       "      <th>com_delta_received</th>\n",
       "      <th>com_delta_from_op</th>\n",
       "      <th>com_upvotes</th>\n",
       "      <th>tokenized_com</th>\n",
       "      <th>normalized_com</th>\n",
       "      <th>tokenized_sub</th>\n",
       "      <th>normalized_sub</th>\n",
       "      <th>tuple</th>\n",
       "      <th>KL</th>\n",
       "      <th>JS</th>\n",
       "      <th>sub_text_y</th>\n",
       "      <th>reduced_tokens</th>\n",
       "      <th>kmeans</th>\n",
       "      <th>kmeans_inter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cas07fi</th>\n",
       "      <td>Here is why. The Emperor had an extraordinary ...</td>\n",
       "      <td>I'm not familiar with the EU, but based on you...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>[I, 'm, not, familiar, with, the, EU, ,, but, ...</td>\n",
       "      <td>[familiar, eu, base, descript, end, justifi, m...</td>\n",
       "      <td>[Here, is, why, ., The, Emperor, had, an, extr...</td>\n",
       "      <td>[whi, emperor, extraordinari, foresight, attac...</td>\n",
       "      <td>(Here is why. The Emperor had an extraordinary...</td>\n",
       "      <td>0.493464</td>\n",
       "      <td>0.110792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3uo9sy</th>\n",
       "      <td>To start, I'm probably going to mostly use my ...</td>\n",
       "      <td>The vast majority of redditors on /r/$TOPIC ar...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, vast, majority, of, redditors, on, /r/, ...</td>\n",
       "      <td>[vast, major, redditor, topic, complet, unqual...</td>\n",
       "      <td>[To, start, ,, I, 'm, probably, going, to, mos...</td>\n",
       "      <td>[start, probabl, go, use, comment, becaus, eas...</td>\n",
       "      <td>(To start, I'm probably going to mostly use my...</td>\n",
       "      <td>0.387678</td>\n",
       "      <td>0.093431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6ab2b8</th>\n",
       "      <td>First up, I'm not suggesting any kind of legal...</td>\n",
       "      <td>Men's macho behavior escalates in male-only pl...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>[Men, 's, macho, behavior, escalates, in, male...</td>\n",
       "      <td>[men, macho, behavior, escal, place, prison, n...</td>\n",
       "      <td>[First, up, ,, I, 'm, not, suggesting, any, ki...</td>\n",
       "      <td>[first, suggest, ani, kind, legal, otherwis, t...</td>\n",
       "      <td>(First up, I'm not suggesting any kind of lega...</td>\n",
       "      <td>0.141931</td>\n",
       "      <td>0.038501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sub_text_x  \\\n",
       "com_id                                                       \n",
       "cas07fi  Here is why. The Emperor had an extraordinary ...   \n",
       "d3uo9sy  To start, I'm probably going to mostly use my ...   \n",
       "d6ab2b8  First up, I'm not suggesting any kind of legal...   \n",
       "\n",
       "                                                  com_text com_delta_received  \\\n",
       "com_id                                                                          \n",
       "cas07fi  I'm not familiar with the EU, but based on you...              False   \n",
       "d3uo9sy  The vast majority of redditors on /r/$TOPIC ar...              False   \n",
       "d6ab2b8  Men's macho behavior escalates in male-only pl...              False   \n",
       "\n",
       "        com_delta_from_op  com_upvotes  \\\n",
       "com_id                                   \n",
       "cas07fi             False            3   \n",
       "d3uo9sy             False            1   \n",
       "d6ab2b8             False            1   \n",
       "\n",
       "                                             tokenized_com  \\\n",
       "com_id                                                       \n",
       "cas07fi  [I, 'm, not, familiar, with, the, EU, ,, but, ...   \n",
       "d3uo9sy  [The, vast, majority, of, redditors, on, /r/, ...   \n",
       "d6ab2b8  [Men, 's, macho, behavior, escalates, in, male...   \n",
       "\n",
       "                                            normalized_com  \\\n",
       "com_id                                                       \n",
       "cas07fi  [familiar, eu, base, descript, end, justifi, m...   \n",
       "d3uo9sy  [vast, major, redditor, topic, complet, unqual...   \n",
       "d6ab2b8  [men, macho, behavior, escal, place, prison, n...   \n",
       "\n",
       "                                             tokenized_sub  \\\n",
       "com_id                                                       \n",
       "cas07fi  [Here, is, why, ., The, Emperor, had, an, extr...   \n",
       "d3uo9sy  [To, start, ,, I, 'm, probably, going, to, mos...   \n",
       "d6ab2b8  [First, up, ,, I, 'm, not, suggesting, any, ki...   \n",
       "\n",
       "                                            normalized_sub  \\\n",
       "com_id                                                       \n",
       "cas07fi  [whi, emperor, extraordinari, foresight, attac...   \n",
       "d3uo9sy  [start, probabl, go, use, comment, becaus, eas...   \n",
       "d6ab2b8  [first, suggest, ani, kind, legal, otherwis, t...   \n",
       "\n",
       "                                                     tuple        KL  \\\n",
       "com_id                                                                 \n",
       "cas07fi  (Here is why. The Emperor had an extraordinary...  0.493464   \n",
       "d3uo9sy  (To start, I'm probably going to mostly use my...  0.387678   \n",
       "d6ab2b8  (First up, I'm not suggesting any kind of lega...  0.141931   \n",
       "\n",
       "               JS sub_text_y reduced_tokens  kmeans kmeans_inter  \n",
       "com_id                                                            \n",
       "cas07fi  0.110792        NaN            NaN     NaN          NaN  \n",
       "d3uo9sy  0.093431        NaN            NaN     NaN          NaN  \n",
       "d6ab2b8  0.038501        NaN            NaN     NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 1: try classification for all posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2014, 15995)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn the training dataset into a tf-idf matrix\n",
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, ngram_range=(1, 10),stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(data_train['com_text'])\n",
    "TFVects.shape #(2055, 5802)\n",
    "#print(TFVects.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15985</th>\n",
       "      <th>15986</th>\n",
       "      <th>15987</th>\n",
       "      <th>15988</th>\n",
       "      <th>15989</th>\n",
       "      <th>15990</th>\n",
       "      <th>15991</th>\n",
       "      <th>15992</th>\n",
       "      <th>15993</th>\n",
       "      <th>15994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 15995 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   ...    15985  15986  15987  15988  15989  15990  15991  15992  15993  15994  \n",
       "0  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 15995 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining tfidf features with liguistic features and clustering labels\n",
    "tfdf = pd.DataFrame(TFVects.toarray())\n",
    "features_train = pd.concat([tfdf, data_train[['com_upvotes', 'KL', 'JS', 'kmeans']]], axis = 1, ignore_index = False)\n",
    "features_test = pd.concat([tfdf, data_test[['com_upvotes', 'KL', 'JS', 'kmeans']]], axis = 1, ignore_index = False)\n",
    "features_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1d53a797d6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#perform pca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mPCA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreduced_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         X = check_array(X, dtype=[np.float64], ensure_2d=True,\n\u001b[0;32m--> 346\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#Perform PCA on this matrix to pick significant features\n",
    "#perform pca\n",
    "PCA = sklearn.decomposition.PCA\n",
    "pca = PCA().fit(features_train)\n",
    "reduced_data = pca.transform(features_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pandas/indexes/range.py:432: RuntimeWarning: unorderable types: int() < str(), sort order is undefined for incomparable objects\n",
      "  return self._int64index.union(other)\n"
     ]
    }
   ],
   "source": [
    "#use scree plot to determine the number of dimensions\n",
    "n = TFVects.shape[0]\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "eigen_vals = np.arange(n) + 1\n",
    "ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "ax1.set_title('Scree Plot')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "eigen_vals = np.arange(20) + 1\n",
    "ax2.plot(eigen_vals, pca.explained_variance_ratio_[:20], 'ro-', linewidth=2)\n",
    "ax2.set_title('Scree Plot (First 20 Principal Components)')\n",
    "ax2.set_xlabel('Principal Component')\n",
    "ax2.set_ylabel('Proportion of Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform pca\n",
    "PCA = sklearn.decomposition.PCA\n",
    "pca = PCA().fit(features_train)\n",
    "reduced_data = pca.transform(TFVects.toarray())\n",
    "\n",
    "#turn the test dataset into a tf-idf\n",
    "TFVects_test = TFVectorizer.transform(data_test['com_text'])\n",
    "#print(TFVects_test.shape)\n",
    "reduced_data_test = pca.transform(TFVects_test.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCA was not able to separate delta-receiving comments and others at all.\n",
    "#use scree plot to determine the number of dimensions\n",
    "n = TFVects.shape[0]\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "eigen_vals = np.arange(n) + 1\n",
    "ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "ax1.set_title('Scree Plot')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "eigen_vals = np.arange(20) + 1\n",
    "ax2.plot(eigen_vals, pca.explained_variance_ratio_[:20], 'ro-', linewidth=2)\n",
    "ax2.set_title('Scree Plot (First 20 Principal Components)')\n",
    "ax2.set_xlabel('Principal Component')\n",
    "ax2.set_ylabel('Proportion of Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting with first ten\n",
    "X = reduced_data[:, :10]\n",
    "Y = np.array([int(label) for label in data_train['com_delta_received']]) #Transform our predictor variable. \n",
    "              \n",
    "#fitting logistic regresion\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(X, Y)\n",
    "print(\"This logistic model using top ten components fits {} of our training set\".format(logistic.score(X,Y)))\n",
    "\n",
    "X_test = reduced_data_test[:, :10]\n",
    "Y_test = np.array([int(label) for label in data_test['com_delta_received']])\n",
    "print(\"This logistic model using top ten components fits {} of our testing set\".format(logistic.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 2: try classification sparately for each \"cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

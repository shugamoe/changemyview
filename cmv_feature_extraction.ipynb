{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.datasets import fetch_20newsgroups, make_blobs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  #Feature extraction\n",
    "from sklearn.naive_bayes import MultinomialNB #Our learner.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif, SelectFromModel\n",
    "import pandas as pd\n",
    "\n",
    "import nltk #For tokenizing and normalizing\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_pickle('cmv_full_features.pkl')\n",
    "#df = df.sample(frac = .1)\n",
    "#splitting data\n",
    "data_train, data_test = train_test_split(df, test_size=0.3, random_state=123)\n",
    "data_train['is_train'] = True\n",
    "data_test['is_train'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26852, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn the training dataset into a tf-idf matrix\n",
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_features = 10000, ngram_range=(1, 10),stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(data_train['com_text'])\n",
    "TFVects.shape #(3836, 32241)\n",
    "#print(TFVects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perform SVD on this matrix to reduce dimensionality\n",
    "\n",
    "# SVD = TruncatedSVD(n_components=1000, random_state=123)\n",
    "# reduced_data = SVD.fit_transform(TFVects)\n",
    "# reduced_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining tfidf features with liguistic features and clustering labels\n",
    "tfdf = pd.DataFrame(TFVects.toarray())\n",
    "features_train = pd.concat([tfdf, data_train.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "features_train.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#turn the test dataset into a tf-idf\n",
    "TFVects_test = TFVectorizer.transform(data_test['com_text'])\n",
    "#reduced_test = SVD.transform(TFVects_test)\n",
    "tfdf_test = pd.DataFrame(TFVects_test.toarray())\n",
    "features_test = pd.concat([tfdf_test, data_test.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "features_test.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features_train\n",
    "y = data_train['com_delta_received'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 1: try classification for all posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combining tfidf features with liguistic features and clustering labels\n",
    "# tfdf = pd.DataFrame(TFVects.toarray())\n",
    "# features_train = pd.concat([tfdf, data_train.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "# features_train.set_index('index', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use scree plot to determine the number of dimensions\n",
    "# n = TFVects.shape[0]\n",
    "# fig = plt.figure(figsize=(12,5))\n",
    "# ax1 = fig.add_subplot(121)\n",
    "# eigen_vals = np.arange(n) + 1\n",
    "# ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "# ax1.set_title('Scree Plot')\n",
    "# ax1.set_xlabel('Principal Component')\n",
    "# ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "# ax2 = fig.add_subplot(122)\n",
    "# eigen_vals = np.arange(10) + 1\n",
    "# ax2.plot(eigen_vals, pca.explained_variance_ratio_[:10], 'ro-', linewidth=2)\n",
    "# ax2.set_title('Scree Plot (First 20 Principal Components)')\n",
    "# ax2.set_xlabel('Principal Component')\n",
    "# ax2.set_ylabel('Proportion of Explained Variance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicting with first ten\n",
    "# X = reduced_data[:, :2]\n",
    "# Y = np.array([int(label) for label in data_train['com_delta_received']]) #Transform our predictor variable. \n",
    "              \n",
    "#fitting logistic regresion\n",
    "# logistic = linear_model.LogisticRegression()\n",
    "# logistic.fit(X, Y)\n",
    "# print(\"This logistic model using top two components fits {} of our training set\".format(logistic.score(X,Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #turn the test dataset into a tf-idf\n",
    "# TFVects_test = TFVectorizer.transform(data_test['com_text'])\n",
    "# tfdf_test = pd.DataFrame(TFVects_test.toarray())\n",
    "# features_test = pd.concat([tfdf_test, data_test.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "# features_test.set_index('index', inplace = True)\n",
    "# reduced_data_test = pca.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_test = reduced_data_test[:, :2]\n",
    "# Y_test = np.array([int(label) for label in data_test['com_delta_received']])\n",
    "# print(\"This logistic model using top ten components fits {} of our testing set\".format(logistic.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Evaluation stats\n",
    "# print(\"Precision:\", sklearn.metrics.precision_score(Y, logistic.predict(X), average = 'weighted')) #precision\n",
    "# print(\"Recall:\",sklearn.metrics.recall_score(Y, logistic.predict(X), average = 'weighted')) #recall\n",
    "# print(\"F-measure:\",sklearn.metrics.f1_score(Y, logistic.predict(X), average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #ROC curve\n",
    "# x, y, _ = sklearn.metrics.roc_curve(Y, logistic.predict_proba(X)[:,1])\n",
    "# roc_auc = sklearn.metrics.auc(x,y)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(x,y, color = 'darkorange', lw = 2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Problem: we lost track of the feature names after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binary Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tree = DecisionTreeClassifier(max_depth=4,random_state=0).fit(reduced_data, data_train['com_delta_received'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels = tree.predict(reduced_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mat = confusion_matrix(data_test['com_delta_received'], labels)\n",
    "# seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#                 xticklabels=['delta_not_received', 'delta_received'], yticklabels=['delta_not_received', 'delta_received'])\n",
    "# plt.xlabel('true label')\n",
    "# plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('Precision: {}'.format(sklearn.metrics.precision_score(data_test['com_delta_received'], labels, average = 'weighted'))) \n",
    "# print('Recall: {}'.format(sklearn.metrics.recall_score(data_test['com_delta_received'], labels, average = 'weighted'))) \n",
    "# print('F1 Score: {}'.format(sklearn.metrics.f1_score(data_test['com_delta_received'], labels, average = 'weighted'))) \n",
    "\n",
    "# labels = [1 if dr else 0 for dr in labels]\n",
    "# probs = tree.predict_proba(reduced_data_test)\n",
    "# print('AUC Score: {}'.format(sklearn.metrics.roc_auc_score(data_test['com_delta_received'], probs[:,1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets - multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #initialize the model\n",
    "# mlp_clf = MLPClassifier()\n",
    "\n",
    "# fit the model\n",
    "# mlp_clf.fit(X, y)\n",
    "\n",
    "# #mlp_labels = [mlp_clf.predict(v)[0] for v in features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Confusion matrix\n",
    "# mat = confusion_matrix(data_test['com_delta_received'], mlp_labels)\n",
    "# seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#                 xticklabels=['delta_not_received', 'delta_received'], yticklabels=['delta_not_received', 'delta_received'])\n",
    "# plt.xlabel('true label')\n",
    "# plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_test['com_delta_received']\n",
    "#mlp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #ROC curve\n",
    "# x, y, _ = sklearn.metrics.roc_curve(data_test['com_delta_received'], mlp_labels)\n",
    "# roc_auc = sklearn.metrics.auc(x,y)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(x,y, color = 'darkorange', lw = 2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 2: try classification sparately for each \"cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Feature extraction\n",
    "\n",
    "Idea: We realized that none of the implementations of the machine learning algorithms actually provides us with the list of features that are most reliable to classify comments. Thus, we are using feature extraction tools from sklearn.\n",
    "\n",
    "Oh, we've observed that the features are very stable across algorithms, we could interpret these features by finding them in comments and see if these comments receive delta or not\n",
    "\n",
    "## feature extraction using SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_KBest(func, k):\n",
    "    selector = SelectKBest(func, k=k).fit(X,y)\n",
    "    feature_indices = selector.get_support(indices=True)\n",
    "    \n",
    "    selected_features = features_train.columns[feature_indices].get_values()\n",
    "    scores = selector.scores_[feature_indices]\n",
    "    if selector.pvalues_ != None:\n",
    "        pvalues = selector.pvalues_[feature_indices]\n",
    "    else:\n",
    "        pvalues = None\n",
    "    return (selected_features, scores, pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([187, 253, 376, 695, 1857, 2139, 2158, 3290, 3385, 3583, 4271, 4850,\n",
       "       5531, 6113, 6121, 7440, 'com_upvotes', 'KL', 'JS',\n",
       "       'com_avg_pt_depth'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f_classif\n",
    "selected_features_f, scores_f, pvalues_f = extract_KBest(sklearn.feature_selection.f_classif, 20)\n",
    "selected_features_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features_f</th>\n",
       "      <th>pvalues_f</th>\n",
       "      <th>scores_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2598.615876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large group</td>\n",
       "      <td>1.635654e-13</td>\n",
       "      <td>54.456131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JS</td>\n",
       "      <td>2.971789e-13</td>\n",
       "      <td>53.280571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KL</td>\n",
       "      <td>3.674229e-13</td>\n",
       "      <td>52.862969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outrage</td>\n",
       "      <td>4.733387e-13</td>\n",
       "      <td>52.364524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mexican</td>\n",
       "      <td>8.204640e-13</td>\n",
       "      <td>51.282426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outcomes</td>\n",
       "      <td>1.344589e-10</td>\n",
       "      <td>41.275076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>audiences</td>\n",
       "      <td>2.990624e-10</td>\n",
       "      <td>39.710802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airline</td>\n",
       "      <td>5.830431e-10</td>\n",
       "      <td>38.405535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>accountable</td>\n",
       "      <td>1.000888e-09</td>\n",
       "      <td>37.349810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>contrast</td>\n",
       "      <td>1.093914e-09</td>\n",
       "      <td>37.176251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flight</td>\n",
       "      <td>1.384566e-09</td>\n",
       "      <td>36.716207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>1.437484e-09</td>\n",
       "      <td>36.642989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deer</td>\n",
       "      <td>3.414774e-09</td>\n",
       "      <td>34.955075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>repeated</td>\n",
       "      <td>4.733607e-09</td>\n",
       "      <td>34.318523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>important</td>\n",
       "      <td>5.007291e-09</td>\n",
       "      <td>34.208997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>additional</td>\n",
       "      <td>1.441491e-08</td>\n",
       "      <td>32.150429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>female</td>\n",
       "      <td>1.568123e-08</td>\n",
       "      <td>31.986655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decision making</td>\n",
       "      <td>2.071256e-08</td>\n",
       "      <td>31.445568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gay community</td>\n",
       "      <td>4.426237e-08</td>\n",
       "      <td>29.970372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      all_features_f     pvalues_f     scores_f\n",
       "0        com_upvotes  0.000000e+00  2598.615876\n",
       "1        large group  1.635654e-13    54.456131\n",
       "2                 JS  2.971789e-13    53.280571\n",
       "3                 KL  3.674229e-13    52.862969\n",
       "4            outrage  4.733387e-13    52.364524\n",
       "5            mexican  8.204640e-13    51.282426\n",
       "6           outcomes  1.344589e-10    41.275076\n",
       "7          audiences  2.990624e-10    39.710802\n",
       "8            airline  5.830431e-10    38.405535\n",
       "9        accountable  1.000888e-09    37.349810\n",
       "10          contrast  1.093914e-09    37.176251\n",
       "11            flight  1.384566e-09    36.716207\n",
       "12  com_avg_pt_depth  1.437484e-09    36.642989\n",
       "13              deer  3.414774e-09    34.955075\n",
       "14          repeated  4.733607e-09    34.318523\n",
       "15         important  5.007291e-09    34.208997\n",
       "16        additional  1.441491e-08    32.150429\n",
       "17            female  1.568123e-08    31.986655\n",
       "18   decision making  2.071256e-08    31.445568\n",
       "19     gay community  4.426237e-08    29.970372"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_features_indices_f = selected_features_f[:-4].astype(int)\n",
    "all_features_f  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_f].tolist()\n",
    "all_features_f.extend(selected_features_f[-4:])\n",
    "#all_features_f\n",
    "d = {'all_features_f': all_features_f, 'scores_f': scores_f, 'pvalues_f': pvalues_f}\n",
    "F_f_DF = pd.DataFrame(data = d).sort(columns='scores_f', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_f_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chi2 - we can't use this algo because some values of upvotes are negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([405, 1634, 2488, 2560, 3980, 4665, 5072, 5095, 5191, 5268, 5803,\n",
       "       6632, 6717, 6815, 8881, 9012, 9294, 9913, 'com_upvotes',\n",
       "       'com_avg_pt_depth'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mutual_info_classif\n",
    "selected_features_m, scores_m, pvalues_m = extract_KBest(mutual_info_classif, 20)\n",
    "selected_features_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvalues_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features_m</th>\n",
       "      <th>scores_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.029531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>things</td>\n",
       "      <td>0.004259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just</td>\n",
       "      <td>0.004141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>does</td>\n",
       "      <td>0.003941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>point</td>\n",
       "      <td>0.003561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>need</td>\n",
       "      <td>0.003190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pretty</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>make</td>\n",
       "      <td>0.003133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time</td>\n",
       "      <td>0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>list goes</td>\n",
       "      <td>0.002971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>likely</td>\n",
       "      <td>0.002960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>post</td>\n",
       "      <td>0.002928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>worst</td>\n",
       "      <td>0.002898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>help</td>\n",
       "      <td>0.002865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lot</td>\n",
       "      <td>0.002842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>allergies</td>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>comment rule don rude hostile users comment</td>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>don</td>\n",
       "      <td>0.002827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>unequal</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 all_features_m  scores_m\n",
       "0                                   com_upvotes  0.029531\n",
       "1                                        things  0.004259\n",
       "2                                          just  0.004141\n",
       "3                                          does  0.003941\n",
       "4                                         point  0.003561\n",
       "5                              com_avg_pt_depth  0.003424\n",
       "6                                          need  0.003190\n",
       "7                                        pretty  0.003175\n",
       "8                                          make  0.003133\n",
       "9                                          time  0.003096\n",
       "10                                    list goes  0.002971\n",
       "11                                       likely  0.002960\n",
       "12                                         post  0.002928\n",
       "13                                        worst  0.002898\n",
       "14                                         help  0.002865\n",
       "15                                          lot  0.002842\n",
       "16                                    allergies  0.002830\n",
       "17  comment rule don rude hostile users comment  0.002828\n",
       "18                                          don  0.002827\n",
       "19                                      unequal  0.002779"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_features_indices_m = selected_features_m[:-2].astype(int)\n",
    "all_features_m  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_m].tolist()\n",
    "all_features_m.extend(selected_features_m[-2:])\n",
    "#all_features_m\n",
    "d = {'all_features_m': all_features_m, 'scores_m': scores_m}\n",
    "F_m_DF = pd.DataFrame(data = d).sort(columns='scores_m', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_m_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_m_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction using Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_model(clf_fitted):\n",
    "    feature_indices = SelectFromModel(clf_fitted, prefit=True).get_support(indices=True)\n",
    "    try:\n",
    "        score = clf_fitted.feature_importances_[feature_indices]\n",
    "    except:\n",
    "        score = None\n",
    "    selected_features = features_train.columns[feature_indices].get_values()\n",
    "    return (selected_features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decision tree\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129, 200, 253, 347, 377, 460, 463, 481, 529, 1176, 1857, 2118, 2348,\n",
       "       2459, 2491, 2560, 2601, 2658, 3085, 3122, 3435, 3594, 3598, 3661,\n",
       "       3754, 3892, 3961, 4665, 4890, 5022, 5446, 5596, 5748, 6121, 6298,\n",
       "       6596, 6704, 6926, 6957, 7376, 7509, 7701, 7976, 7992, 8077, 8100,\n",
       "       8170, 8255, 8536, 8825, 8828, 8859, 8881, 8904, 9453, 9684, 9731,\n",
       "       9872, 9917, 9962, 'com_upvotes'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_t1, scores_t1 = extract_model(tree_clf)\n",
    "selected_features_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features_t1</th>\n",
       "      <th>scores_t1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.400377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sold</td>\n",
       "      <td>0.025940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>additional</td>\n",
       "      <td>0.019782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theoretically</td>\n",
       "      <td>0.018814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>extra</td>\n",
       "      <td>0.017462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>difficult</td>\n",
       "      <td>0.017413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>giving</td>\n",
       "      <td>0.017193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>annoying</td>\n",
       "      <td>0.016848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airlines</td>\n",
       "      <td>0.016255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>animal</td>\n",
       "      <td>0.016221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>candidate</td>\n",
       "      <td>0.015493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>position</td>\n",
       "      <td>0.015429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>shouldn</td>\n",
       "      <td>0.015371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>worth</td>\n",
       "      <td>0.014538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>contrast</td>\n",
       "      <td>0.014414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9962</td>\n",
       "      <td>0.014303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>think</td>\n",
       "      <td>0.014144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>heard</td>\n",
       "      <td>0.013487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>terrorists</td>\n",
       "      <td>0.013070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dozen</td>\n",
       "      <td>0.012686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   all_features_t1  scores_t1\n",
       "0      com_upvotes   0.400377\n",
       "1             sold   0.025940\n",
       "2       additional   0.019782\n",
       "3    theoretically   0.018814\n",
       "4            extra   0.017462\n",
       "5        difficult   0.017413\n",
       "6           giving   0.017193\n",
       "7         annoying   0.016848\n",
       "8         airlines   0.016255\n",
       "9           animal   0.016221\n",
       "10       candidate   0.015493\n",
       "11        position   0.015429\n",
       "12         shouldn   0.015371\n",
       "13           worth   0.014538\n",
       "14        contrast   0.014414\n",
       "15            9962   0.014303\n",
       "16           think   0.014144\n",
       "17           heard   0.013487\n",
       "18      terrorists   0.013070\n",
       "19           dozen   0.012686"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_features_indices_t1 = selected_features_t1[:-2].astype(int)\n",
    "all_features_t1  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_t1].tolist()\n",
    "all_features_t1.extend(selected_features_t1[-2:])\n",
    "#all_features_t1\n",
    "\n",
    "d = {'all_features_t1': all_features_t1, 'scores_t1': scores_t1}\n",
    "F_t1_DF = pd.DataFrame(data = d).sort(columns='scores_t1', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_t1_DF.iloc[:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extra decision tree\n",
    "#fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset \n",
    "#and use averaging to improve the predictive accuracy and control over-fitting\n",
    "tree2_clf = ExtraTreesClassifier(n_estimators=250,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features_t2, scores_t2 = extract_model(tree2_clf)\n",
    "#selected_features_t2[2700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selected_features_t2[2600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliazhou/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features_t2</th>\n",
       "      <th>scores_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.019197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>0.002823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KL</td>\n",
       "      <td>0.002605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JS</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>think</td>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>people</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>just</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>don</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>good</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>way</td>\n",
       "      <td>0.001192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>make</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>point</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>square</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>isn</td>\n",
       "      <td>0.001008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lot</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>say</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>really</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>does</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     all_features_t2  scores_t2\n",
       "0        com_upvotes   0.019197\n",
       "1   com_avg_pt_depth   0.002823\n",
       "2                 KL   0.002605\n",
       "3                 JS   0.002588\n",
       "4             kmeans   0.002266\n",
       "5              think   0.001842\n",
       "6             people   0.001700\n",
       "7               just   0.001634\n",
       "8                don   0.001416\n",
       "9               like   0.001358\n",
       "10              good   0.001200\n",
       "11               way   0.001192\n",
       "12              make   0.001159\n",
       "13             point   0.001037\n",
       "14            square   0.001012\n",
       "15               isn   0.001008\n",
       "16               lot   0.000996\n",
       "17               say   0.000987\n",
       "18            really   0.000986\n",
       "19              does   0.000977"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_features_indices_t2 = selected_features_t2[:-5].astype(int)\n",
    "all_features_t2  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_t2].tolist()\n",
    "all_features_t2.extend(selected_features_t2[-5:])\n",
    "#all_features_t1\n",
    "\n",
    "d = {'all_features_t2': all_features_t2, 'scores_t2': scores_t2}\n",
    "F_t2_DF = pd.DataFrame(data = d).sort(columns='scores_t2', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_t2_DF.iloc[:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_features_f</th>\n",
       "      <th>pvalues_f</th>\n",
       "      <th>scores_f</th>\n",
       "      <th>all_features_m</th>\n",
       "      <th>scores_m</th>\n",
       "      <th>all_features_t1</th>\n",
       "      <th>scores_t1</th>\n",
       "      <th>all_features_t2</th>\n",
       "      <th>scores_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2598.615876</td>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.400377</td>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.019197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large group</td>\n",
       "      <td>1.635654e-13</td>\n",
       "      <td>54.456131</td>\n",
       "      <td>things</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>sold</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>0.002823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JS</td>\n",
       "      <td>2.971789e-13</td>\n",
       "      <td>53.280571</td>\n",
       "      <td>just</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>additional</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>KL</td>\n",
       "      <td>0.002605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KL</td>\n",
       "      <td>3.674229e-13</td>\n",
       "      <td>52.862969</td>\n",
       "      <td>does</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>theoretically</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outrage</td>\n",
       "      <td>4.733387e-13</td>\n",
       "      <td>52.364524</td>\n",
       "      <td>point</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>extra</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mexican</td>\n",
       "      <td>8.204640e-13</td>\n",
       "      <td>51.282426</td>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>difficult</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>think</td>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outcomes</td>\n",
       "      <td>1.344589e-10</td>\n",
       "      <td>41.275076</td>\n",
       "      <td>need</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>giving</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>people</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>audiences</td>\n",
       "      <td>2.990624e-10</td>\n",
       "      <td>39.710802</td>\n",
       "      <td>pretty</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>annoying</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>just</td>\n",
       "      <td>0.001634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airline</td>\n",
       "      <td>5.830431e-10</td>\n",
       "      <td>38.405535</td>\n",
       "      <td>make</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>airlines</td>\n",
       "      <td>0.016255</td>\n",
       "      <td>don</td>\n",
       "      <td>0.001416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>accountable</td>\n",
       "      <td>1.000888e-09</td>\n",
       "      <td>37.349810</td>\n",
       "      <td>time</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.016221</td>\n",
       "      <td>like</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>contrast</td>\n",
       "      <td>1.093914e-09</td>\n",
       "      <td>37.176251</td>\n",
       "      <td>list goes</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>candidate</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>good</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flight</td>\n",
       "      <td>1.384566e-09</td>\n",
       "      <td>36.716207</td>\n",
       "      <td>likely</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>position</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>way</td>\n",
       "      <td>0.001192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>1.437484e-09</td>\n",
       "      <td>36.642989</td>\n",
       "      <td>post</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>shouldn</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>make</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deer</td>\n",
       "      <td>3.414774e-09</td>\n",
       "      <td>34.955075</td>\n",
       "      <td>worst</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>worth</td>\n",
       "      <td>0.014538</td>\n",
       "      <td>point</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>repeated</td>\n",
       "      <td>4.733607e-09</td>\n",
       "      <td>34.318523</td>\n",
       "      <td>help</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>contrast</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>square</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>important</td>\n",
       "      <td>5.007291e-09</td>\n",
       "      <td>34.208997</td>\n",
       "      <td>lot</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>9962</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>isn</td>\n",
       "      <td>0.001008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>additional</td>\n",
       "      <td>1.441491e-08</td>\n",
       "      <td>32.150429</td>\n",
       "      <td>allergies</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>think</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>lot</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>female</td>\n",
       "      <td>1.568123e-08</td>\n",
       "      <td>31.986655</td>\n",
       "      <td>comment rule don rude hostile users comment</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>heard</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>say</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decision making</td>\n",
       "      <td>2.071256e-08</td>\n",
       "      <td>31.445568</td>\n",
       "      <td>don</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>terrorists</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>really</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gay community</td>\n",
       "      <td>4.426237e-08</td>\n",
       "      <td>29.970372</td>\n",
       "      <td>unequal</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>dozen</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>does</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      all_features_f     pvalues_f     scores_f  \\\n",
       "0        com_upvotes  0.000000e+00  2598.615876   \n",
       "1        large group  1.635654e-13    54.456131   \n",
       "2                 JS  2.971789e-13    53.280571   \n",
       "3                 KL  3.674229e-13    52.862969   \n",
       "4            outrage  4.733387e-13    52.364524   \n",
       "5            mexican  8.204640e-13    51.282426   \n",
       "6           outcomes  1.344589e-10    41.275076   \n",
       "7          audiences  2.990624e-10    39.710802   \n",
       "8            airline  5.830431e-10    38.405535   \n",
       "9        accountable  1.000888e-09    37.349810   \n",
       "10          contrast  1.093914e-09    37.176251   \n",
       "11            flight  1.384566e-09    36.716207   \n",
       "12  com_avg_pt_depth  1.437484e-09    36.642989   \n",
       "13              deer  3.414774e-09    34.955075   \n",
       "14          repeated  4.733607e-09    34.318523   \n",
       "15         important  5.007291e-09    34.208997   \n",
       "16        additional  1.441491e-08    32.150429   \n",
       "17            female  1.568123e-08    31.986655   \n",
       "18   decision making  2.071256e-08    31.445568   \n",
       "19     gay community  4.426237e-08    29.970372   \n",
       "\n",
       "                                 all_features_m  scores_m all_features_t1  \\\n",
       "0                                   com_upvotes  0.029531     com_upvotes   \n",
       "1                                        things  0.004259            sold   \n",
       "2                                          just  0.004141      additional   \n",
       "3                                          does  0.003941   theoretically   \n",
       "4                                         point  0.003561           extra   \n",
       "5                              com_avg_pt_depth  0.003424       difficult   \n",
       "6                                          need  0.003190          giving   \n",
       "7                                        pretty  0.003175        annoying   \n",
       "8                                          make  0.003133        airlines   \n",
       "9                                          time  0.003096          animal   \n",
       "10                                    list goes  0.002971       candidate   \n",
       "11                                       likely  0.002960        position   \n",
       "12                                         post  0.002928         shouldn   \n",
       "13                                        worst  0.002898           worth   \n",
       "14                                         help  0.002865        contrast   \n",
       "15                                          lot  0.002842            9962   \n",
       "16                                    allergies  0.002830           think   \n",
       "17  comment rule don rude hostile users comment  0.002828           heard   \n",
       "18                                          don  0.002827      terrorists   \n",
       "19                                      unequal  0.002779           dozen   \n",
       "\n",
       "    scores_t1   all_features_t2  scores_t2  \n",
       "0    0.400377       com_upvotes   0.019197  \n",
       "1    0.025940  com_avg_pt_depth   0.002823  \n",
       "2    0.019782                KL   0.002605  \n",
       "3    0.018814                JS   0.002588  \n",
       "4    0.017462            kmeans   0.002266  \n",
       "5    0.017413             think   0.001842  \n",
       "6    0.017193            people   0.001700  \n",
       "7    0.016848              just   0.001634  \n",
       "8    0.016255               don   0.001416  \n",
       "9    0.016221              like   0.001358  \n",
       "10   0.015493              good   0.001200  \n",
       "11   0.015429               way   0.001192  \n",
       "12   0.015371              make   0.001159  \n",
       "13   0.014538             point   0.001037  \n",
       "14   0.014414            square   0.001012  \n",
       "15   0.014303               isn   0.001008  \n",
       "16   0.014144               lot   0.000996  \n",
       "17   0.013487               say   0.000987  \n",
       "18   0.013070            really   0.000986  \n",
       "19   0.012686              does   0.000977  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_DF = pd.concat([F_f_DF, F_m_DF, F_t1_DF.iloc[:20, :], F_t2_DF.iloc[:20, :]], axis =1)\n",
    "F_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_DF.to_pickle('extracted_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Feature extraction using Neural nets - mlp\n",
    "\n",
    "# log_clf = linear_model.LogisticRegression()\n",
    "# log_clf.fit(X, y)\n",
    "# selected_features_log, scores_log = extract_model(log_clf)\n",
    "# selected_features_log.shape\n",
    "# selected_features_log[4500:]\n",
    "# tf_features_indices_log = selected_features_log[:-1].astype(int)\n",
    "# all_features_log = np.array(TFVectorizer.get_feature_names())[tf_features_indices_log].tolist()\n",
    "# all_features_log.extend(selected_features_log[-1:])\n",
    "#all_features_t1\n",
    "\n",
    "# d = {'all_features_log': all_features_log, 'scores_log': scores_log}\n",
    "# F_log_DF = pd.DataFrame(data = d).sort(columns='scores_log', axis=0, ascending=False).reset_index(drop = True)\n",
    "# F_log_DF.iloc[:20, :]\n",
    "#log_decisionDF = pd.DataFrame(log_clf.decision_function(X))#.sort(columns = [0], ascending = False)\n",
    "#log_clf.densify("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F_DF.to_pickle(\"extracted_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ef = pandas.read_pickle('extracted_features.pkl')\n",
    "#ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I still want to get the real words, let me try to do it from here\n",
    "\n",
    "Basically, \n",
    "- <b>TFVects</b> is the huge sparse matrix that cannot be convert to a dense matrix\n",
    "- <b>reduced_data</b> is the dense matrix that has 1000 ngram features\n",
    "- <b>features_train</b> is the dataframe that has 1000 ngram features + others we obtained\n",
    "\n",
    "The problem is that I know the indices of the ngrams in <b>features_train</b>, and I want to figure out what these indices correspond to in <b>TFVects</b>, the huge sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f_classif\n",
    "# selected_features_f, scores_f, pvalues_f = extract_KBest(sklearn.feature_selection.f_classif, 20)\n",
    "# selected_features_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_features_indices_f = selected_features_f[:-1].astype(int)\n",
    "#-> indices within the 1000 dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_features_f  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_f].tolist()\n",
    "# all_features_f.append(selected_features_f[-1])\n",
    "# all_features_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d = {'selected_features_f': selected_features_f, 'scores_f': scores_f, 'pvalues_f': pvalues_f}\n",
    "# F_f_DF = pd.DataFrame(data = d).sort(columns='scores_f', axis=0, ascending=False).reset_index(drop = True)\n",
    "# F_f_DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

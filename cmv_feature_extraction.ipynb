{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.datasets import fetch_20newsgroups, make_blobs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  #Feature extraction\n",
    "from sklearn.naive_bayes import MultinomialNB #Our learner.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif, SelectFromModel\n",
    "import pandas as pd\n",
    "\n",
    "import nltk #For tokenizing and normalizing\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_pickle('cmv_full_features.pkl')\n",
    "df = df.sample(frac = .1)\n",
    "#splitting data\n",
    "data_train, data_test = train_test_split(df, test_size=0.3, random_state=123)\n",
    "data_train['is_train'] = True\n",
    "data_test['is_train'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2685, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn the training dataset into a tf-idf matrix\n",
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_features = 10000, ngram_range=(1, 10),stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(data_train['com_text'])\n",
    "TFVects.shape #(3836, 32241)\n",
    "#print(TFVects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2685, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform SVD on this matrix to reduce dimensionality\n",
    "\n",
    "# SVD = TruncatedSVD(n_components=1000, random_state=123)\n",
    "# reduced_data = SVD.fit_transform(TFVects)\n",
    "# reduced_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining tfidf features with liguistic features and clustering labels\n",
    "tfdf = pd.DataFrame(TFVects.toarray())\n",
    "features_train = pd.concat([tfdf, data_train.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "features_train.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#turn the test dataset into a tf-idf\n",
    "TFVects_test = TFVectorizer.transform(data_test['com_text'])\n",
    "#reduced_test = SVD.transform(TFVects_test)\n",
    "tfdf_test = pd.DataFrame(TFVects_test.toarray())\n",
    "features_test = pd.concat([tfdf_test, data_test.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "features_test.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features_train\n",
    "y = data_train['com_delta_received'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 1: try classification for all posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combining tfidf features with liguistic features and clustering labels\n",
    "# tfdf = pd.DataFrame(TFVects.toarray())\n",
    "# features_train = pd.concat([tfdf, data_train.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "# features_train.set_index('index', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use scree plot to determine the number of dimensions\n",
    "# n = TFVects.shape[0]\n",
    "# fig = plt.figure(figsize=(12,5))\n",
    "# ax1 = fig.add_subplot(121)\n",
    "# eigen_vals = np.arange(n) + 1\n",
    "# ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "# ax1.set_title('Scree Plot')\n",
    "# ax1.set_xlabel('Principal Component')\n",
    "# ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "# ax2 = fig.add_subplot(122)\n",
    "# eigen_vals = np.arange(10) + 1\n",
    "# ax2.plot(eigen_vals, pca.explained_variance_ratio_[:10], 'ro-', linewidth=2)\n",
    "# ax2.set_title('Scree Plot (First 20 Principal Components)')\n",
    "# ax2.set_xlabel('Principal Component')\n",
    "# ax2.set_ylabel('Proportion of Explained Variance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicting with first ten\n",
    "# X = reduced_data[:, :2]\n",
    "# Y = np.array([int(label) for label in data_train['com_delta_received']]) #Transform our predictor variable. \n",
    "              \n",
    "#fitting logistic regresion\n",
    "# logistic = linear_model.LogisticRegression()\n",
    "# logistic.fit(X, Y)\n",
    "# print(\"This logistic model using top two components fits {} of our training set\".format(logistic.score(X,Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #turn the test dataset into a tf-idf\n",
    "# TFVects_test = TFVectorizer.transform(data_test['com_text'])\n",
    "# tfdf_test = pd.DataFrame(TFVects_test.toarray())\n",
    "# features_test = pd.concat([tfdf_test, data_test.reset_index()[['index', 'com_upvotes', 'KL', 'JS', 'kmeans', 'com_avg_pt_depth']]], axis = 1, ignore_index = False)\n",
    "# features_test.set_index('index', inplace = True)\n",
    "# reduced_data_test = pca.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_test = reduced_data_test[:, :2]\n",
    "# Y_test = np.array([int(label) for label in data_test['com_delta_received']])\n",
    "# print(\"This logistic model using top ten components fits {} of our testing set\".format(logistic.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Evaluation stats\n",
    "# print(\"Precision:\", sklearn.metrics.precision_score(Y, logistic.predict(X), average = 'weighted')) #precision\n",
    "# print(\"Recall:\",sklearn.metrics.recall_score(Y, logistic.predict(X), average = 'weighted')) #recall\n",
    "# print(\"F-measure:\",sklearn.metrics.f1_score(Y, logistic.predict(X), average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #ROC curve\n",
    "# x, y, _ = sklearn.metrics.roc_curve(Y, logistic.predict_proba(X)[:,1])\n",
    "# roc_auc = sklearn.metrics.auc(x,y)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(x,y, color = 'darkorange', lw = 2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Problem: we lost track of the feature names after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binary Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tree = DecisionTreeClassifier(max_depth=4,random_state=0).fit(reduced_data, data_train['com_delta_received'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels = tree.predict(reduced_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mat = confusion_matrix(data_test['com_delta_received'], labels)\n",
    "# seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#                 xticklabels=['delta_not_received', 'delta_received'], yticklabels=['delta_not_received', 'delta_received'])\n",
    "# plt.xlabel('true label')\n",
    "# plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('Precision: {}'.format(sklearn.metrics.precision_score(data_test['com_delta_received'], labels, average = 'weighted'))) \n",
    "# print('Recall: {}'.format(sklearn.metrics.recall_score(data_test['com_delta_received'], labels, average = 'weighted'))) \n",
    "# print('F1 Score: {}'.format(sklearn.metrics.f1_score(data_test['com_delta_received'], labels, average = 'weighted'))) \n",
    "\n",
    "# labels = [1 if dr else 0 for dr in labels]\n",
    "# probs = tree.predict_proba(reduced_data_test)\n",
    "# print('AUC Score: {}'.format(sklearn.metrics.roc_auc_score(data_test['com_delta_received'], probs[:,1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets - multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #initialize the model\n",
    "# mlp_clf = MLPClassifier()\n",
    "\n",
    "# fit the model\n",
    "# mlp_clf.fit(X, y)\n",
    "\n",
    "# #mlp_labels = [mlp_clf.predict(v)[0] for v in features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Confusion matrix\n",
    "# mat = confusion_matrix(data_test['com_delta_received'], mlp_labels)\n",
    "# seaborn.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#                 xticklabels=['delta_not_received', 'delta_received'], yticklabels=['delta_not_received', 'delta_received'])\n",
    "# plt.xlabel('true label')\n",
    "# plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_test['com_delta_received']\n",
    "#mlp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #ROC curve\n",
    "# x, y, _ = sklearn.metrics.roc_curve(data_test['com_delta_received'], mlp_labels)\n",
    "# roc_auc = sklearn.metrics.auc(x,y)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(x,y, color = 'darkorange', lw = 2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic curve')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 2: try classification sparately for each \"cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Feature extraction\n",
    "\n",
    "Idea: We realized that none of the implementations of the machine learning algorithms actually provides us with the list of features that are most reliable to classify comments. Thus, we are using feature extraction tools from sklearn.\n",
    "\n",
    "Oh, we've observed that the features are very stable across algorithms, we could interpret these features by finding them in comments and see if these comments receive delta or not\n",
    "\n",
    "## feature extraction using SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_KBest(func, k):\n",
    "    selector = SelectKBest(func, k=k).fit(X,y)\n",
    "    feature_indices = selector.get_support(indices=True)\n",
    "    \n",
    "    selected_features = features_train.columns[feature_indices].get_values()\n",
    "    scores = selector.scores_[feature_indices]\n",
    "    if selector.pvalues_ != None:\n",
    "        pvalues = selector.pvalues_[feature_indices]\n",
    "    else:\n",
    "        pvalues = None\n",
    "    return (selected_features, scores, pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f_classif\n",
    "selected_features_f, scores_f, pvalues_f = extract_KBest(sklearn.feature_selection.f_classif, 20)\n",
    "selected_features_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_features_indices_f = selected_features_f[:-1].astype(int)\n",
    "all_features_f  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_f].tolist()\n",
    "all_features_f.append(selected_features_f[-1])\n",
    "#all_features_f\n",
    "d = {'selected_features_f': selected_features_f, 'scores_f': scores_f, 'pvalues_f': pvalues_f}\n",
    "F_f_DF = pd.DataFrame(data = d).sort(columns='scores_f', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_f_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chi2 - we can't use this algo because some values of upvotes are negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mutual_info_classif\n",
    "selected_features_m, scores_m, pvalues_m = extract_KBest(mutual_info_classif, 20)\n",
    "selected_features_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvalues_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_features_indices_m = selected_features_m[:-1].astype(int)\n",
    "all_features_m  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_m].tolist()\n",
    "all_features_m.extend(selected_features_m[-1:])\n",
    "#all_features_m\n",
    "d = {'selected_features_m': selected_features_m, 'scores_m': scores_m}\n",
    "F_m_DF = pd.DataFrame(data = d).sort(columns='scores_m', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_m_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_m_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction using Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_model(clf_fitted):\n",
    "    feature_indices = SelectFromModel(clf_fitted, prefit=True).get_support(indices=True)\n",
    "    try:\n",
    "        score = clf_fitted.feature_importances_[feature_indices]\n",
    "    except:\n",
    "        score = None\n",
    "    selected_features = features_train.columns[feature_indices].get_values()\n",
    "    return (selected_features, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decision tree\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features_t1, scores_t1 = extract_model(tree_clf)\n",
    "selected_features_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_features_indices_t1 = selected_features_t1[:-2].astype(int)\n",
    "all_features_t1  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_t1].tolist()\n",
    "all_features_t1.extend(selected_features_t1[-2:])\n",
    "#all_features_t1\n",
    "\n",
    "d = {'selected_features_t1': selected_features_t1, 'scores_t1': scores_t1}\n",
    "F_t1_DF = pd.DataFrame(data = d).sort(columns='scores_t1', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_t1_DF.iloc[:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extra decision tree\n",
    "#fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset \n",
    "#and use averaging to improve the predictive accuracy and control over-fitting\n",
    "tree2_clf = ExtraTreesClassifier(n_estimators=250,random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features_t2, scores_t2 = extract_model(tree2_clf)\n",
    "#selected_features_t2[2700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selected_features_t2[2600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_features_indices_t2 = selected_features_t2[:-5].astype(int)\n",
    "all_features_t2  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_t2].tolist()\n",
    "all_features_t2.extend(selected_features_t2[-5:])\n",
    "#all_features_t1\n",
    "\n",
    "d = {'selected_features_t2': selected_features_t2, 'scores_t2': scores_t2}\n",
    "F_t2_DF = pd.DataFrame(data = d).sort(columns='scores_t2', axis=0, ascending=False).reset_index(drop = True)\n",
    "F_t2_DF.iloc[:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_DF = pd.concat([F_f_DF, F_m_DF, F_t1_DF.iloc[:20, :], F_t2_DF.iloc[:20, :]], axis =1)\n",
    "F_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Feature extraction using Neural nets - mlp\n",
    "\n",
    "# log_clf = linear_model.LogisticRegression()\n",
    "# log_clf.fit(X, y)\n",
    "# selected_features_log, scores_log = extract_model(log_clf)\n",
    "# selected_features_log.shape\n",
    "# selected_features_log[4500:]\n",
    "# tf_features_indices_log = selected_features_log[:-1].astype(int)\n",
    "# all_features_log = np.array(TFVectorizer.get_feature_names())[tf_features_indices_log].tolist()\n",
    "# all_features_log.extend(selected_features_log[-1:])\n",
    "#all_features_t1\n",
    "\n",
    "# d = {'all_features_log': all_features_log, 'scores_log': scores_log}\n",
    "# F_log_DF = pd.DataFrame(data = d).sort(columns='scores_log', axis=0, ascending=False).reset_index(drop = True)\n",
    "# F_log_DF.iloc[:20, :]\n",
    "#log_decisionDF = pd.DataFrame(log_clf.decision_function(X))#.sort(columns = [0], ascending = False)\n",
    "#log_clf.densify(ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_DF.to_pickle(\"extracted_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvalues_f</th>\n",
       "      <th>scores_f</th>\n",
       "      <th>selected_features_f</th>\n",
       "      <th>scores_m</th>\n",
       "      <th>selected_features_m</th>\n",
       "      <th>scores_t1</th>\n",
       "      <th>selected_features_t1</th>\n",
       "      <th>scores_t2</th>\n",
       "      <th>selected_features_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2598.615876</td>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.029173</td>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.248368</td>\n",
       "      <td>com_upvotes</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>com_upvotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.795970e-60</td>\n",
       "      <td>270.443076</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025082</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.971789e-13</td>\n",
       "      <td>53.280571</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>341</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.674229e-13</td>\n",
       "      <td>52.862969</td>\n",
       "      <td>KL</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015484</td>\n",
       "      <td>616</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.437484e-09</td>\n",
       "      <td>36.642989</td>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>8</td>\n",
       "      <td>0.015049</td>\n",
       "      <td>143</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.767745e-06</td>\n",
       "      <td>20.002018</td>\n",
       "      <td>248</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>280</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.100916e-05</td>\n",
       "      <td>19.335121</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>453</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.849321e-05</td>\n",
       "      <td>16.511506</td>\n",
       "      <td>553</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>13</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>435</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.171193e-05</td>\n",
       "      <td>16.389600</td>\n",
       "      <td>149</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>6</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>896</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.249823e-04</td>\n",
       "      <td>14.720291</td>\n",
       "      <td>404</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>com_avg_pt_depth</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>329</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.447750e-04</td>\n",
       "      <td>14.443125</td>\n",
       "      <td>347</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>9</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>530</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.189572e-04</td>\n",
       "      <td>13.664710</td>\n",
       "      <td>28</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>46</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>363</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.361927e-04</td>\n",
       "      <td>13.522398</td>\n",
       "      <td>562</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>10</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>798</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.746104e-04</td>\n",
       "      <td>13.239598</td>\n",
       "      <td>75</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>305</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.002015e-04</td>\n",
       "      <td>12.534411</td>\n",
       "      <td>372</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>19</td>\n",
       "      <td>0.012118</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.194203e-04</td>\n",
       "      <td>12.047548</td>\n",
       "      <td>86</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>931</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.360837e-04</td>\n",
       "      <td>11.398481</td>\n",
       "      <td>263</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>36</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>935</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>KL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.293964e-04</td>\n",
       "      <td>11.176801</td>\n",
       "      <td>319</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>28</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>498</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>JS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.896149e-04</td>\n",
       "      <td>10.849289</td>\n",
       "      <td>314</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>JS</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>350</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.130025e-03</td>\n",
       "      <td>10.603684</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>KL</td>\n",
       "      <td>0.011434</td>\n",
       "      <td>424</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pvalues_f     scores_f selected_features_f  scores_m  \\\n",
       "0   0.000000e+00  2598.615876         com_upvotes  0.029173   \n",
       "1   1.795970e-60   270.443076                   2  0.006716   \n",
       "2   2.971789e-13    53.280571                  JS  0.006125   \n",
       "3   3.674229e-13    52.862969                  KL  0.005891   \n",
       "4   1.437484e-09    36.642989    com_avg_pt_depth  0.005411   \n",
       "5   7.767745e-06    20.002018                 248  0.005364   \n",
       "6   1.100916e-05    19.335121                   3  0.004977   \n",
       "7   4.849321e-05    16.511506                 553  0.004642   \n",
       "8   5.171193e-05    16.389600                 149  0.004641   \n",
       "9   1.249823e-04    14.720291                 404  0.004118   \n",
       "10  1.447750e-04    14.443125                 347  0.003938   \n",
       "11  2.189572e-04    13.664710                  28  0.003726   \n",
       "12  2.361927e-04    13.522398                 562  0.003548   \n",
       "13  2.746104e-04    13.239598                  75  0.003526   \n",
       "14  4.002015e-04    12.534411                 372  0.003519   \n",
       "15  5.194203e-04    12.047548                  86  0.003273   \n",
       "16  7.360837e-04    11.398481                 263  0.003113   \n",
       "17  8.293964e-04    11.176801                 319  0.003054   \n",
       "18  9.896149e-04    10.849289                 314  0.003011   \n",
       "19  1.130025e-03    10.603684                  29  0.002916   \n",
       "\n",
       "   selected_features_m  scores_t1 selected_features_t1  scores_t2  \\\n",
       "0          com_upvotes   0.248368          com_upvotes   0.029779   \n",
       "1                    2   0.025082                    4   0.002256   \n",
       "2                    4   0.022398                  341   0.002035   \n",
       "3                    3   0.015484                  616   0.001906   \n",
       "4                    8   0.015049                  143   0.001873   \n",
       "5                    0   0.014497                  280   0.001866   \n",
       "6                    5   0.014274                  453   0.001843   \n",
       "7                   13   0.013842                  435   0.001824   \n",
       "8                    6   0.013674                  896   0.001761   \n",
       "9     com_avg_pt_depth   0.013339                  329   0.001754   \n",
       "10                   9   0.013069                  530   0.001652   \n",
       "11                  46   0.012862                  363   0.001616   \n",
       "12                  10   0.012336                  798   0.001605   \n",
       "13                 305   0.012250                  500   0.001599   \n",
       "14                  19   0.012118               kmeans   0.001588   \n",
       "15                   1   0.012093                  931   0.001578   \n",
       "16                  36   0.011989                  935   0.001565   \n",
       "17                  28   0.011965                  498   0.001556   \n",
       "18                  JS   0.011571                  350   0.001520   \n",
       "19                  KL   0.011434                  424   0.001513   \n",
       "\n",
       "   selected_features_t2  \n",
       "0           com_upvotes  \n",
       "1                     2  \n",
       "2                     4  \n",
       "3                    30  \n",
       "4                    28  \n",
       "5                     8  \n",
       "6                     5  \n",
       "7                     7  \n",
       "8                    19  \n",
       "9                    18  \n",
       "10                   31  \n",
       "11                   34  \n",
       "12                   27  \n",
       "13                    0  \n",
       "14                    6  \n",
       "15                   24  \n",
       "16                   KL  \n",
       "17                   JS  \n",
       "18                   14  \n",
       "19                   44  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ef = pandas.read_pickle('extracted_features.pkl')\n",
    "#ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I still want to get the real words, let me try to do it from here\n",
    "\n",
    "Basically, \n",
    "- <b>TFVects</b> is the huge sparse matrix that cannot be convert to a dense matrix\n",
    "- <b>reduced_data</b> is the dense matrix that has 1000 ngram features\n",
    "- <b>features_train</b> is the dataframe that has 1000 ngram features + others we obtained\n",
    "\n",
    "The problem is that I know the indices of the ngrams in <b>features_train</b>, and I want to figure out what these indices correspond to in <b>TFVects</b>, the huge sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 14, 65, 81, 160, 191, 304, 319, 397, 417, 448, 523, 588, 695,\n",
       "       705, 827, 951, 959, 980, 'com_upvotes'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f_classif\n",
    "# selected_features_f, scores_f, pvalues_f = extract_KBest(sklearn.feature_selection.f_classif, 20)\n",
    "# selected_features_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_features_indices_f = selected_features_f[:-1].astype(int)\n",
    "#-> indices within the 1000 dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 21560)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_features_f  = np.array(TFVectorizer.get_feature_names())[tf_features_indices_f].tolist()\n",
    "# all_features_f.append(selected_features_f[-1])\n",
    "# all_features_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d = {'selected_features_f': selected_features_f, 'scores_f': scores_f, 'pvalues_f': pvalues_f}\n",
    "# F_f_DF = pd.DataFrame(data = d).sort(columns='scores_f', axis=0, ascending=False).reset_index(drop = True)\n",
    "# F_f_DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
